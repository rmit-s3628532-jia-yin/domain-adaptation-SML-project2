{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "male_df = pd.read_csv(\"../Data-Project2/MALE.csv\")\n",
    "female_df = pd.read_csv(\"../Data-Project2/FEMALE.csv\")\n",
    "mixed_df = pd.read_csv(\"../Data-Project2/MIXED.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>FSM</th>\n",
       "      <th>VR1 Band</th>\n",
       "      <th>VR Band of Student</th>\n",
       "      <th>Ethnic group of student</th>\n",
       "      <th>School denomination</th>\n",
       "      <th>Exam Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310356</td>\n",
       "      <td>-0.115156</td>\n",
       "      <td>-0.012401</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>-0.054839</td>\n",
       "      <td>0.030357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSM</th>\n",
       "      <td>0.310356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.663802</td>\n",
       "      <td>-0.057669</td>\n",
       "      <td>0.143429</td>\n",
       "      <td>-0.195003</td>\n",
       "      <td>-0.145205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VR1 Band</th>\n",
       "      <td>-0.115156</td>\n",
       "      <td>-0.663802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055520</td>\n",
       "      <td>-0.114039</td>\n",
       "      <td>0.239845</td>\n",
       "      <td>0.189623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VR Band of Student</th>\n",
       "      <td>-0.012401</td>\n",
       "      <td>-0.057669</td>\n",
       "      <td>0.055520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040201</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>0.122282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethnic group of student</th>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.143429</td>\n",
       "      <td>-0.114039</td>\n",
       "      <td>-0.040201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050347</td>\n",
       "      <td>0.035312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>School denomination</th>\n",
       "      <td>-0.054839</td>\n",
       "      <td>-0.195003</td>\n",
       "      <td>0.239845</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>0.050347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exam Score</th>\n",
       "      <td>0.030357</td>\n",
       "      <td>-0.145205</td>\n",
       "      <td>0.189623</td>\n",
       "      <td>0.122282</td>\n",
       "      <td>0.035312</td>\n",
       "      <td>0.110279</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Year       FSM  VR1 Band  VR Band of Student  \\\n",
       "Year                     1.000000  0.310356 -0.115156           -0.012401   \n",
       "FSM                      0.310356  1.000000 -0.663802           -0.057669   \n",
       "VR1 Band                -0.115156 -0.663802  1.000000            0.055520   \n",
       "VR Band of Student      -0.012401 -0.057669  0.055520            1.000000   \n",
       "Ethnic group of student  0.016566  0.143429 -0.114039           -0.040201   \n",
       "School denomination     -0.054839 -0.195003  0.239845            0.015157   \n",
       "Exam Score               0.030357 -0.145205  0.189623            0.122282   \n",
       "\n",
       "                         Ethnic group of student  School denomination  \\\n",
       "Year                                    0.016566            -0.054839   \n",
       "FSM                                     0.143429            -0.195003   \n",
       "VR1 Band                               -0.114039             0.239845   \n",
       "VR Band of Student                     -0.040201             0.015157   \n",
       "Ethnic group of student                 1.000000             0.050347   \n",
       "School denomination                     0.050347             1.000000   \n",
       "Exam Score                              0.035312             0.110279   \n",
       "\n",
       "                         Exam Score  \n",
       "Year                       0.030357  \n",
       "FSM                       -0.145205  \n",
       "VR1 Band                   0.189623  \n",
       "VR Band of Student         0.122282  \n",
       "Ethnic group of student    0.035312  \n",
       "School denomination        0.110279  \n",
       "Exam Score                 1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "male_df.head()\n",
    "\n",
    "## correlation matrix\n",
    "corr = mixed_df.corr()\n",
    "plt.figure(figsize = (8,8))\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "# data_copy.dtypes\n",
    "# data_copy.head()\n",
    "mixed_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7289, 7)\n"
     ]
    }
   ],
   "source": [
    "mixed_df['VR Band of Student'].value_counts()\n",
    "\n",
    "### remove rows where \"VR Band of Student\" is 0, since the meaning of \"0\" is unknown\n",
    "mixed_df.drop(mixed_df[mixed_df['VR Band of Student'] == 0].index, inplace = True) \n",
    "mixed_df['VR Band of Student'].value_counts()\n",
    "\n",
    "print(mixed_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### one hot encoding a column\n",
    "def one_hot_encoding(df, column):\n",
    "    # Get one hot encoding of column B\n",
    "    one_hot = pd.get_dummies(df[column], prefix=column)\n",
    "    # Drop column B as it is now encoded\n",
    "    new_df = df.drop(column, axis = 1)\n",
    "    # Join the encoded df\n",
    "    return new_df.join(one_hot)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>VR1 Band</th>\n",
       "      <th>Exam Score</th>\n",
       "      <th>Ethnic group of student_1</th>\n",
       "      <th>Ethnic group of student_2</th>\n",
       "      <th>Ethnic group of student_3</th>\n",
       "      <th>Ethnic group of student_4</th>\n",
       "      <th>Ethnic group of student_5</th>\n",
       "      <th>Ethnic group of student_6</th>\n",
       "      <th>Ethnic group of student_7</th>\n",
       "      <th>Ethnic group of student_8</th>\n",
       "      <th>Ethnic group of student_9</th>\n",
       "      <th>Ethnic group of student_10</th>\n",
       "      <th>Ethnic group of student_11</th>\n",
       "      <th>School denomination_1</th>\n",
       "      <th>School denomination_2</th>\n",
       "      <th>School denomination_3</th>\n",
       "      <th>VR Band of Student_1</th>\n",
       "      <th>VR Band of Student_2</th>\n",
       "      <th>VR Band of Student_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  VR1 Band  Exam Score  Ethnic group of student_1  \\\n",
       "0     1        21          20                          1   \n",
       "1     1        21          12                          1   \n",
       "2     1        21          16                          1   \n",
       "3     1        21          10                          0   \n",
       "4     1        21           9                          1   \n",
       "\n",
       "   Ethnic group of student_2  Ethnic group of student_3  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   Ethnic group of student_4  Ethnic group of student_5  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          1   \n",
       "4                          0                          0   \n",
       "\n",
       "   Ethnic group of student_6  Ethnic group of student_7  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   Ethnic group of student_8  Ethnic group of student_9  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   Ethnic group of student_10  Ethnic group of student_11  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   School denomination_1  School denomination_2  School denomination_3  \\\n",
       "0                      0                      1                      0   \n",
       "1                      0                      1                      0   \n",
       "2                      0                      1                      0   \n",
       "3                      0                      1                      0   \n",
       "4                      0                      1                      0   \n",
       "\n",
       "   VR Band of Student_1  VR Band of Student_2  VR Band of Student_3  \n",
       "0                     0                     1                     0  \n",
       "1                     0                     0                     1  \n",
       "2                     1                     0                     0  \n",
       "3                     0                     0                     1  \n",
       "4                     0                     0                     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## one hot encode categorical features\n",
    "male_df = one_hot_encoding(male_df, 'Ethnic group of student')\n",
    "male_df = one_hot_encoding(male_df, 'School denomination')\n",
    "\n",
    "female_df = one_hot_encoding(female_df, 'Ethnic group of student')\n",
    "female_df = one_hot_encoding(female_df, 'School denomination')\n",
    "\n",
    "mixed_df = one_hot_encoding(mixed_df, 'Ethnic group of student')\n",
    "mixed_df = one_hot_encoding(mixed_df, 'School denomination')\n",
    "\n",
    "## one hot encode vr band of student\n",
    "male_df = one_hot_encoding(male_df, 'VR Band of Student')\n",
    "female_df = one_hot_encoding(female_df, 'VR Band of Student')\n",
    "mixed_df = one_hot_encoding(mixed_df, 'VR Band of Student')\n",
    "\n",
    "# drop FSM because it's an irrelevant feature\n",
    "male_df = male_df.drop(columns=['FSM'])\n",
    "female_df = female_df.drop(columns=['FSM'])\n",
    "mixed_df = mixed_df.drop(columns=['FSM'])\n",
    "\n",
    "male_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split data into training, development and test partitions\n",
    "def split_data(df):\n",
    "    data = {}\n",
    "    \n",
    "    X = df.drop(columns=['Exam Score'])\n",
    "    y = df['Exam Score']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.11, random_state=1)\n",
    "    \n",
    "    data['X_train'] = X_train\n",
    "    data['X_dev'] = X_dev\n",
    "    data['X_test'] = X_test\n",
    "    data['y_train'] = y_train\n",
    "    data['y_dev'] = y_dev\n",
    "    data['y_test'] = y_test\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2926, 19)\n",
      "(3527, 19)\n",
      "(5838, 19)\n",
      "(362, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>VR1 Band</th>\n",
       "      <th>Ethnic group of student_1</th>\n",
       "      <th>Ethnic group of student_2</th>\n",
       "      <th>Ethnic group of student_3</th>\n",
       "      <th>Ethnic group of student_4</th>\n",
       "      <th>Ethnic group of student_5</th>\n",
       "      <th>Ethnic group of student_6</th>\n",
       "      <th>Ethnic group of student_7</th>\n",
       "      <th>Ethnic group of student_8</th>\n",
       "      <th>Ethnic group of student_9</th>\n",
       "      <th>Ethnic group of student_10</th>\n",
       "      <th>Ethnic group of student_11</th>\n",
       "      <th>School denomination_1</th>\n",
       "      <th>School denomination_2</th>\n",
       "      <th>School denomination_3</th>\n",
       "      <th>VR Band of Student_1</th>\n",
       "      <th>VR Band of Student_2</th>\n",
       "      <th>VR Band of Student_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  VR1 Band  Ethnic group of student_1  Ethnic group of student_2  \\\n",
       "2058     1        38                          0                          0   \n",
       "1123     2        25                          0                          0   \n",
       "766      2        25                          1                          0   \n",
       "1510     2        27                          0                          0   \n",
       "2380     3        11                          0                          0   \n",
       "\n",
       "      Ethnic group of student_3  Ethnic group of student_4  \\\n",
       "2058                          0                          0   \n",
       "1123                          0                          0   \n",
       "766                           0                          0   \n",
       "1510                          0                          0   \n",
       "2380                          0                          0   \n",
       "\n",
       "      Ethnic group of student_5  Ethnic group of student_6  \\\n",
       "2058                          1                          0   \n",
       "1123                          1                          0   \n",
       "766                           0                          0   \n",
       "1510                          0                          0   \n",
       "2380                          0                          0   \n",
       "\n",
       "      Ethnic group of student_7  Ethnic group of student_8  \\\n",
       "2058                          0                          0   \n",
       "1123                          0                          0   \n",
       "766                           0                          0   \n",
       "1510                          0                          1   \n",
       "2380                          0                          1   \n",
       "\n",
       "      Ethnic group of student_9  Ethnic group of student_10  \\\n",
       "2058                          0                           0   \n",
       "1123                          0                           0   \n",
       "766                           0                           0   \n",
       "1510                          0                           0   \n",
       "2380                          0                           0   \n",
       "\n",
       "      Ethnic group of student_11  School denomination_1  \\\n",
       "2058                           0                      0   \n",
       "1123                           0                      1   \n",
       "766                            0                      0   \n",
       "1510                           0                      1   \n",
       "2380                           0                      1   \n",
       "\n",
       "      School denomination_2  School denomination_3  VR Band of Student_1  \\\n",
       "2058                      0                      1                     0   \n",
       "1123                      0                      0                     0   \n",
       "766                       0                      1                     1   \n",
       "1510                      0                      0                     0   \n",
       "2380                      0                      0                     1   \n",
       "\n",
       "      VR Band of Student_2  VR Band of Student_3  \n",
       "2058                     1                     0  \n",
       "1123                     0                     1  \n",
       "766                      0                     0  \n",
       "1510                     0                     1  \n",
       "2380                     0                     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {}\n",
    "\n",
    "data_dict['male'] = split_data(male_df)\n",
    "data_dict['female'] = split_data(female_df)\n",
    "data_dict['mixed'] = split_data(mixed_df)\n",
    "\n",
    "\n",
    "print(data_dict['male']['X_train'].shape)\n",
    "print(data_dict['female']['X_train'].shape)\n",
    "print(data_dict['mixed']['X_train'].shape)\n",
    "\n",
    "print(data_dict['male']['X_dev'].shape)\n",
    "\n",
    "\n",
    "# print(data_dict['female']['X_dev'].shape)\n",
    "# print(data_dict['female']['X_test'].shape)\n",
    "\n",
    "# print(data_dict['female']['y_train'].shape)\n",
    "# print(data_dict['female']['y_dev'].shape)\n",
    "# print(data_dict['female']['y_test'].shape)\n",
    "data_dict['male']['X_train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_100_instances(target, partition, data_dict):\n",
    "    return data_dict[target][partition].iloc[:100]\n",
    "\n",
    "# add columns for a domain which is member of {general, male, female, mixed}\n",
    "def add_columns_for_one_domain(is_zero_vector, df, domain, column_names):  \n",
    "    \n",
    "    new_df = df.copy()\n",
    "    n_rows = new_df.shape[0]\n",
    "    zero_list = [0] * n_rows\n",
    "    \n",
    "    general_df = new_df[column_names]\n",
    "    \n",
    "    if is_zero_vector == True:\n",
    "        for column in general_df:\n",
    "            new_df = new_df.assign(new_column = pd.Series(zero_list).values)\n",
    "            new_df.rename(columns={'new_column': domain + ' ' + column}, inplace=True)\n",
    "    \n",
    "    else:\n",
    "        for column in general_df:\n",
    "            new_df = new_df.assign(new_column = new_df[column].values)\n",
    "            new_df.rename(columns={'new_column': domain + ' ' + column}, inplace=True)\n",
    "            \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feda_augment_feature_space(target, src_domains, data_dict):\n",
    "    first_src_domain = src_domains[0]\n",
    "    second_src_domain = src_domains[1]\n",
    "    \n",
    "    X_train_first_src_domain = data_dict[first_src_domain]['X_train']\n",
    "    X_train_second_src_domain = data_dict[second_src_domain]['X_train']\n",
    "    X_train_target = get_100_instances(target, 'X_train', data_dict)\n",
    "    \n",
    "    column_names = list(X_train_first_src_domain.columns.values)\n",
    "#     print(column_names)\n",
    "    \n",
    "    ## expand feature space for the first source domain         \n",
    "    X_train_first_src_domain = add_columns_for_one_domain(False, X_train_first_src_domain, first_src_domain, column_names) \n",
    "    X_train_first_src_domain = add_columns_for_one_domain(True, X_train_first_src_domain, second_src_domain, column_names)\n",
    "    X_train_first_src_domain = add_columns_for_one_domain(True, X_train_first_src_domain, target, column_names) \n",
    "    ## second source domain\n",
    "    X_train_second_src_domain = add_columns_for_one_domain(True, X_train_second_src_domain, first_src_domain, column_names) \n",
    "    X_train_second_src_domain = add_columns_for_one_domain(False, X_train_second_src_domain, second_src_domain, column_names) \n",
    "    X_train_second_src_domain = add_columns_for_one_domain(True, X_train_second_src_domain, target, column_names) \n",
    "    ## target\n",
    "    X_train_target = add_columns_for_one_domain(True, X_train_target, first_src_domain, column_names) \n",
    "    X_train_target = add_columns_for_one_domain(True, X_train_target, second_src_domain, column_names) \n",
    "    X_train_target = add_columns_for_one_domain(False, X_train_target, target, column_names) \n",
    "    ## concatenate domain data\n",
    "    X_train = pd.concat([X_train_target, X_train_first_src_domain, \n",
    "                             X_train_second_src_domain], ignore_index=True, sort=False)\n",
    "    y_train = pd.concat([get_100_instances(target, 'y_train', data_dict), data_dict[src_domains[0]]['y_train'], \n",
    "                         data_dict[src_domains[1]]['y_train']], ignore_index=True, sort=False)\n",
    "    \n",
    "    ## augment feature space for development and test \n",
    "    X_dev = get_100_instances(target, 'X_dev', data_dict)\n",
    "    y_dev = get_100_instances(target, 'y_dev', data_dict)\n",
    "    \n",
    "    X_test = data_dict[target]['X_test']\n",
    "    y_test = data_dict[target]['y_test']\n",
    "    \n",
    "    X_dev = add_columns_for_one_domain(True, X_dev, first_src_domain, column_names) \n",
    "    X_dev = add_columns_for_one_domain(True, X_dev, second_src_domain, column_names) \n",
    "    X_dev = add_columns_for_one_domain(False, X_dev, target, column_names) \n",
    "    \n",
    "    X_test = add_columns_for_one_domain(True, X_test, first_src_domain, column_names) \n",
    "    X_test = add_columns_for_one_domain(True, X_test, second_src_domain, column_names) \n",
    "    X_test = add_columns_for_one_domain(False, X_test, target, column_names) \n",
    "\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the data partitions for a given target for the ALL baseline\n",
    "def get_data_partitions_for_a_target(target, data_dict, baseline):\n",
    "    X_train = None\n",
    "    y_train = None\n",
    "    \n",
    "    domains = {\"male\", \"female\", \"mixed\"}\n",
    "    src_domains = list(domains.difference({target}))\n",
    "    \n",
    "    assert len(src_domains) == 2\n",
    "    \n",
    "    if baseline == 'FEDA':\n",
    "        X_train, y_train, X_dev, y_dev, X_test, y_test = feda_augment_feature_space(target, src_domains, data_dict)\n",
    "        assert X_train.shape[1] == 76 and X_dev.shape[1] == 76 and X_test.shape[1] == 76\n",
    "        \n",
    "#         display(X_train)\n",
    "#         display(X_dev)\n",
    "#         display(X_test)\n",
    "        return X_train, y_train, X_dev, y_dev, X_test, y_test\n",
    "        \n",
    "    if baseline == 'ALL' or baseline == 'WEIGHTED':\n",
    "        X_train = pd.concat([get_100_instances(target, 'X_train', data_dict), data_dict[src_domains[0]]['X_train'], \n",
    "                             data_dict[src_domains[1]]['X_train']], ignore_index=True, sort=False)\n",
    "        y_train = pd.concat([get_100_instances(target, 'y_train', data_dict), data_dict[src_domains[0]]['y_train'], \n",
    "                         data_dict[src_domains[1]]['y_train']], ignore_index=True, sort=False)\n",
    "    \n",
    "    if baseline == 'SRCONLY':\n",
    "        X_train = pd.concat([data_dict[src_domains[0]]['X_train'], \n",
    "                             data_dict[src_domains[1]]['X_train']], ignore_index=True, sort=False)\n",
    "        y_train = pd.concat([data_dict[src_domains[0]]['y_train'], \n",
    "                         data_dict[src_domains[1]]['y_train']], ignore_index=True, sort=False)\n",
    "    \n",
    "    if baseline == 'TGTONLY':\n",
    "        X_train = get_100_instances(target, 'X_train', data_dict)\n",
    "        y_train = get_100_instances(target, 'y_train', data_dict)\n",
    "        \n",
    "    X_dev = get_100_instances(target, 'X_dev', data_dict)\n",
    "    y_dev = get_100_instances(target, 'y_dev', data_dict)\n",
    "    \n",
    "    X_test = data_dict[target]['X_test']\n",
    "    y_test = data_dict[target]['y_test']\n",
    "        \n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tune parameters\n",
    "def tune_paras_lin_reg(X_train, y_train, X_dev, y_dev, para_grid):\n",
    "    best_model = None\n",
    "    best_mse = float('inf')\n",
    "    best_paras = {\n",
    "        \"alpha\": None,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for alpha in para_grid[\"alpha\"]:\n",
    "        model = Ridge(alpha = alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred = model.predict(X_dev)\n",
    "\n",
    "        mse = mean_squared_error(y_dev, pred)\n",
    "#         print(mse)\n",
    "\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_paras[\"alpha\"] = alpha\n",
    "    \n",
    "            best_model = model\n",
    "                \n",
    "    return best_model, best_mse, best_paras\n",
    "\n",
    "def tune_paras_weighted_lin_reg(X_train, y_train, X_dev, y_dev, para_grid):\n",
    "    best_model = None\n",
    "    best_mse = float('inf')\n",
    "    best_paras = {\n",
    "        \"alpha\": None,\n",
    "        \"weight\": None\n",
    "    }\n",
    "    \n",
    "    n_src_samples = X_train.shape[0] - 100\n",
    "    \n",
    "    for alpha in para_grid[\"alpha\"]:\n",
    "        for weight in para_grid[\"weight\"]:\n",
    "            \n",
    "            sample_weight = [1] * 100 + [weight] * n_src_samples\n",
    "            \n",
    "            model = Ridge(alpha = alpha)\n",
    "            model.fit(X_train, y_train, sample_weight = sample_weight)\n",
    "\n",
    "            pred = model.predict(X_dev)\n",
    "\n",
    "            mse = mean_squared_error(y_dev, pred)\n",
    "#             print(mse)\n",
    "\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_paras[\"alpha\"] = alpha\n",
    "                best_paras[\"weight\"] = weight\n",
    "\n",
    "                best_model = model\n",
    "                \n",
    "    return best_model, best_mse, best_paras\n",
    "\n",
    "def tune_para_performance_summary(best_mse, best_paras, model):\n",
    "    print(model + \":\")\n",
    "    print(\"best mse: \", best_mse)\n",
    "    print(\"best parameters: \", best_paras, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tune parameters for decision tree regressor\n",
    "def tune_paras_decision_tree(X_train, y_train, X_dev, y_dev, para_grid):\n",
    "    best_model = None\n",
    "    best_mse = float('inf')\n",
    "    best_paras = {\n",
    "        \"max_depth\": None,\n",
    "        \"min_samples_split\": None,\n",
    "        \"min_samples_leaf\": None\n",
    "    }\n",
    "        \n",
    "    for max_depth in para_grid[\"max_depth\"]:\n",
    "        for min_samples_split in para_grid[\"min_samples_split\"]:\n",
    "            for min_samples_leaf in para_grid[\"min_samples_leaf\"]:\n",
    "            \n",
    "                model = DecisionTreeRegressor(max_depth = max_depth, min_samples_split = min_samples_split, \n",
    "                                              min_samples_leaf = min_samples_leaf)\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                pred = model.predict(X_dev)\n",
    "\n",
    "                mse = mean_squared_error(y_dev, pred)\n",
    "\n",
    "                if mse < best_mse:\n",
    "                    best_mse = mse\n",
    "                    best_paras[\"max_depth\"] = max_depth\n",
    "                    best_paras[\"min_samples_split\"] = min_samples_split\n",
    "                    best_paras[\"min_samples_leaf\"] = min_samples_leaf\n",
    "\n",
    "                    best_model = model\n",
    "                \n",
    "    return best_model, best_mse, best_paras\n",
    "\n",
    "def tune_paras_weighted_decision_tree(X_train, y_train, X_dev, y_dev, para_grid):\n",
    "    best_model = None\n",
    "    best_mse = float('inf')\n",
    "    best_paras = {\n",
    "        \"max_depth\": None,\n",
    "        \"min_samples_split\": None,\n",
    "        \"min_samples_leaf\": None,\n",
    "        \"weight\": None\n",
    "    }\n",
    "    \n",
    "    n_src_samples = X_train.shape[0] - 100\n",
    "        \n",
    "    for max_depth in para_grid[\"max_depth\"]:\n",
    "        for min_samples_split in para_grid[\"min_samples_split\"]:\n",
    "            for min_samples_leaf in para_grid[\"min_samples_leaf\"]:\n",
    "                for weight in para_grid['weight']:\n",
    "                    sample_weight = [1] * 100 + [weight] * n_src_samples\n",
    "            \n",
    "                    model = DecisionTreeRegressor(max_depth = max_depth, min_samples_split = min_samples_split, \n",
    "                                                  min_samples_leaf = min_samples_leaf)\n",
    "                    model.fit(X_train, y_train, sample_weight = sample_weight)\n",
    "\n",
    "                    pred = model.predict(X_dev)\n",
    "\n",
    "                    mse = mean_squared_error(y_dev, pred)\n",
    "\n",
    "                    if mse < best_mse:\n",
    "                        best_mse = mse\n",
    "                        best_paras[\"max_depth\"] = max_depth\n",
    "                        best_paras[\"min_samples_split\"] = min_samples_split\n",
    "                        best_paras[\"min_samples_leaf\"] = min_samples_leaf\n",
    "                        best_paras[\"weight\"] = weight\n",
    "\n",
    "                        best_model = model\n",
    "                \n",
    "    return best_model, best_mse, best_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate performance for a given target\n",
    "def evaluate_performance_on_test(model, X_test, y_test, model_type):\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    print(model_type + \": \")\n",
    "    print('Mean squared error of the final model on test data: %.2f'\n",
    "      % mean_squared_error(y_test, pred))\n",
    "    return mean_squared_error(y_test, pred)\n",
    "\n",
    "def pipeline_given_target(target, data_dict, para_grid, baseline):\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = get_data_partitions_for_a_target(target, data_dict, baseline)\n",
    "    \n",
    "    ### standardize data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_dev = scaler.transform(X_dev)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    if baseline == 'WEIGHTED':\n",
    "        best_model_LR, best_mse_LR, best_paras_LR = tune_paras_weighted_lin_reg(X_train, y_train, X_dev, y_dev, para_grid)\n",
    "        best_model_DT, best_mse_DT, best_paras_DT = tune_paras_weighted_decision_tree(X_train, y_train, X_dev, y_dev, para_grid)\n",
    "        \n",
    "    else:\n",
    "        best_model_LR, best_mse_LR, best_paras_LR = tune_paras_lin_reg(X_train, y_train, X_dev, y_dev, para_grid)\n",
    "        best_model_DT, best_mse_DT, best_paras_DT = tune_paras_decision_tree(X_train, y_train, X_dev, y_dev, para_grid)\n",
    "        \n",
    "    tune_para_performance_summary(best_mse_LR, best_paras_LR, 'Linear Regression')\n",
    "    tune_para_performance_summary(best_mse_DT, best_paras_DT, 'Decision Tree')\n",
    "\n",
    "    ### evaluate performance on test data\n",
    "    mse_test_LR = evaluate_performance_on_test(best_model_LR, X_test, y_test, 'Linear Regression')\n",
    "    mse_test_DT = evaluate_performance_on_test(best_model_DT, X_test, y_test, 'Decision Tree')\n",
    "        \n",
    "    return best_model_LR, mse_test_LR, best_model_DT, mse_test_DT\n",
    "\n",
    "def get_train_data_for_linint(X_dev, srconly_model, tgtonly_model):\n",
    "    pred_srconly = srconly_model.predict(X_dev)\n",
    "    pred_tgtonly = tgtonly_model.predict(X_dev)\n",
    "    y1_minus_y2 = list(np.array(pred_srconly) - np.array(pred_tgtonly))\n",
    "    \n",
    "    d = {\n",
    "        'y1': pred_srconly, \n",
    "        'y2': pred_tgtonly,\n",
    "        'y1 - y2': y1_minus_y2\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data=d)\n",
    "\n",
    "def linint_pipeline_given_target(target, data_dict, srconly_model, tgtonly_model):\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = get_data_partitions_for_a_target(target, data_dict, 'ALL')\n",
    "    ### standardize data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_dev = scaler.transform(X_dev)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train = get_train_data_for_linint(X_dev, srconly_model, tgtonly_model)\n",
    "        \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_dev)\n",
    "    \n",
    "    coefs = model.coef_\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "#     print(model.coef_)\n",
    "#     print(model.intercept_)\n",
    "    \n",
    "    X_train = get_train_data_for_linint(X_test, srconly_model, tgtonly_model)\n",
    "        \n",
    "    y1 = X_train['y1'].tolist() \n",
    "    y2 = X_train['y2'].tolist() \n",
    "    y1_minus_y2 = X_train['y1 - y2'].tolist()\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    for i in range(0, len(y1)):\n",
    "        result = coefs[0] * y1[i] + coefs[1] * y2[i] + coefs[2] * y1_minus_y2[i] + intercept\n",
    "        pred.append(result)\n",
    "    \n",
    "    print('Mean squared error of the final model: %.2f'\n",
    "          % mean_squared_error(y_test, pred))  \n",
    "    best_mse = mean_squared_error(y_test, pred)\n",
    "    \n",
    "    return best_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEs_LR = {}\n",
    "MSEs_DT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# male is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  139.50296934581695\n",
      "best parameters:  {'alpha': 153} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  135.18528484778213\n",
      "best parameters:  {'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 22} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 125.71\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 127.63\n",
      "\n",
      "# female is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  109.12920180891349\n",
      "best parameters:  {'alpha': 1e-24} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  114.62215562408866\n",
      "best parameters:  {'max_depth': 13, 'min_samples_split': 165, 'min_samples_leaf': 22} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 137.98\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 142.58\n",
      "\n",
      "# mixed is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  101.121875\n",
      "best parameters:  {'alpha': 1e-100} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  119.27147580333921\n",
      "best parameters:  {'max_depth': 11, 'min_samples_split': 162, 'min_samples_leaf': 19} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 102.11\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 106.64\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  SRCONLY\n",
    "###\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "mse_LR = {}\n",
    "mse_DT = {}\n",
    "\n",
    "### tune parameters\n",
    "para_grid_male = {\n",
    "    \"alpha\": [140, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 160],\n",
    "    \"max_depth\": [10, 11, 12, 13, 14, 15, 16, 17],\n",
    "    \"min_samples_split\": [17, 18, 19, 20, 21, 22, 23],\n",
    "    \"min_samples_leaf\": [19, 20, 21, 22, 23, 24, 25, 26]\n",
    "}\n",
    "\n",
    "para_grid_female = {\n",
    "    \"alpha\": [1e-25, 1e-24, 1e-23, 1e-22, 1e-21, 1e-20, 1e-19, 1e-18],\n",
    "    \"max_depth\": [10, 11, 12, 13, 14, 15],\n",
    "    \"min_samples_split\": [162, 163, 164, 165, 166, 167, 168],\n",
    "    \"min_samples_leaf\": [19, 20, 21, 22, 23, 24]\n",
    "}\n",
    "\n",
    "para_grid_mixed = {\n",
    "    \"alpha\": [1e-100, 1e-60, 1e-50, 1e-40, 1e-25, 1e-24, 1e-23, 1e-22, 1e-20],\n",
    "    \"max_depth\": [9, 10, 11, 12, 13],\n",
    "    \"min_samples_split\": [162, 163, 164, 165, 166, 167, 168],\n",
    "    \"min_samples_leaf\": [19, 20, 21, 22, 23, 24]\n",
    "}\n",
    "\n",
    "print(\"# male is target #\\n\")\n",
    "srconly_model_male_LR, mse_LR['male'], srconly_model_male_DT, mse_DT['male'] = pipeline_given_target('male', \n",
    "                                                                                                     data_dict, \n",
    "                                                                                                     para_grid_male, \n",
    "                                                                                                     'SRCONLY')\n",
    "\n",
    "print(\"\\n# female is target #\\n\")\n",
    "srconly_model_female_LR, mse_LR['female'], srconly_model_female_DT, mse_DT['female'] = pipeline_given_target('female', \n",
    "                                                                                                             data_dict, \n",
    "                                                                                                             para_grid_female, \n",
    "                                                                                                             'SRCONLY')\n",
    "\n",
    "print(\"\\n# mixed is target #\\n\")\n",
    "srconly_model_mixed_LR, mse_LR['mixed'], srconly_model_mixed_DT, mse_DT['mixed'] = pipeline_given_target('mixed', \n",
    "                                                                                                         data_dict, \n",
    "                                                                                                         para_grid_mixed, \n",
    "                                                                                                         'SRCONLY')\n",
    "\n",
    "MSEs_LR['srconly'] = mse_LR\n",
    "MSEs_DT['srconly'] = mse_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# male is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  156.78986857630704\n",
      "best parameters:  {'alpha': 4.3} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  145.47125296694813\n",
      "best parameters:  {'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 2} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 126.84\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 141.01\n",
      "\n",
      "# female is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  107.98779459125828\n",
      "best parameters:  {'alpha': 1e-14} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  102.86500247503446\n",
      "best parameters:  {'max_depth': 4, 'min_samples_split': 18, 'min_samples_leaf': 9} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 129.73\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 140.41\n",
      "\n",
      "# mixed is target #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=9.33205e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "best mse:  114.90587061919479\n",
      "best parameters:  {'alpha': 17} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  113.39635173757296\n",
      "best parameters:  {'max_depth': 2, 'min_samples_split': 27, 'min_samples_leaf': 1} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 110.31\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 113.68\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  TGTONLY\n",
    "###\n",
    "\n",
    "mse_LR = {}\n",
    "mse_DT = {}\n",
    "\n",
    "### tune parameters\n",
    "para_grid_male = {\n",
    "    \"alpha\": [3.5, 4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.8, 5, 6, 7, 8, 9, 10],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"min_samples_split\": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4, 5, 6, 8, 10]\n",
    "}\n",
    "\n",
    "para_grid_female = {\n",
    "    \"alpha\": [1e-18, 1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-11, 1e-10, 1e-8, 1e-7, 1e-6],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6],\n",
    "    \"min_samples_split\": [18, 19, 20, 21, 22, 23],\n",
    "    \"min_samples_leaf\": [6, 7, 8, 9, 10, 11, 12, 13]\n",
    "}\n",
    "\n",
    "para_grid_mixed = {\n",
    "    \"alpha\": [1, 5, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"min_samples_split\": [27, 28, 29, 30, 31, 32, 33, 34],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "print(\"# male is target #\\n\")\n",
    "tgtonly_model_male_LR, mse_LR['male'], tgtonly_model_male_DT, mse_DT['male'] = pipeline_given_target('male', \n",
    "                                                                                                     data_dict, \n",
    "                                                                                                     para_grid_male, \n",
    "                                                                                                     'TGTONLY')\n",
    "\n",
    "print(\"\\n# female is target #\\n\")\n",
    "tgtonly_model_female_LR, mse_LR['female'], tgtonly_model_female_DT, mse_DT['female'] = pipeline_given_target('female', \n",
    "                                                                                                             data_dict, \n",
    "                                                                                                             para_grid_female, \n",
    "                                                                                                             'TGTONLY')\n",
    "\n",
    "print(\"\\n# mixed is target #\\n\")\n",
    "tgtonly_model_mixed_LR, mse_LR['mixed'], tgtonly_model_mixed_DT, mse_DT['mixed'] = pipeline_given_target('mixed', \n",
    "                                                                                                         data_dict, \n",
    "                                                                                                         para_grid_mixed, \n",
    "                                                                                                         'TGTONLY')\n",
    "\n",
    "MSEs_LR['tgtonly'] = mse_LR\n",
    "MSEs_DT['tgtonly'] = mse_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# male is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  139.48472583954887\n",
      "best parameters:  {'alpha': 152} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  131.3202181536756\n",
      "best parameters:  {'max_depth': 9, 'min_samples_split': 70, 'min_samples_leaf': 34} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 125.57\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 125.71\n",
      "\n",
      "# female is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  108.82252311526885\n",
      "best parameters:  {'alpha': 1e-17} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  116.0047453139656\n",
      "best parameters:  {'max_depth': 11, 'min_samples_split': 191, 'min_samples_leaf': 37} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 137.59\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 140.12\n",
      "\n",
      "# mixed is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  102.33942413052684\n",
      "best parameters:  {'alpha': 1e-12} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  114.26870433909534\n",
      "best parameters:  {'max_depth': 11, 'min_samples_split': 81, 'min_samples_leaf': 38} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 101.37\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 105.67\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  ALL\n",
    "###\n",
    "mse_LR = {}\n",
    "mse_DT = {}\n",
    "\n",
    "### tune parameters\n",
    "para_grid_male = {\n",
    "    \"alpha\": [140, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 160],\n",
    "    \"max_depth\": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    \"min_samples_split\": [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
    "    \"min_samples_leaf\": [31, 32, 33, 34, 35, 36, 37]\n",
    "}\n",
    "\n",
    "para_grid_female = {\n",
    "    \"alpha\": [1e-18, 1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-10, 1e-8, 1e-7, 1e-6],\n",
    "    \"max_depth\": [9, 10, 11, 12, 14, 16, 18, 20],\n",
    "    \"min_samples_split\": [189, 190, 191, 192, 193, 194, 195],\n",
    "    \"min_samples_leaf\": [34, 35, 36, 37, 38, 39, 40, 41]\n",
    "}\n",
    "\n",
    "para_grid_mixed = {\n",
    "    \"alpha\": [1e-18, 1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-11, 1e-10, 1e-8, 1e-7, 1e-6],\n",
    "    \"max_depth\": [6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    \"min_samples_split\": [79, 80, 81, 82, 83, 84, 85, 86, 87, 88],\n",
    "    \"min_samples_leaf\": [31, 32, 33, 34, 35, 36, 37, 38]\n",
    "}\n",
    "\n",
    "print(\"# male is target #\\n\")\n",
    "all_model_male_LR, mse_LR['male'], all_model_male_DT, mse_DT['male'] = pipeline_given_target('male', \n",
    "                                                                                             data_dict,\n",
    "                                                                                             para_grid_male, \n",
    "                                                                                             'ALL')\n",
    "\n",
    "print(\"\\n# female is target #\\n\")\n",
    "all_model_female_LR, mse_LR['female'], all_model_female_DT, mse_DT['female'] = pipeline_given_target('female', \n",
    "                                                                                                     data_dict, \n",
    "                                                                                                     para_grid_female, \n",
    "                                                                                                     'ALL')\n",
    "\n",
    "print(\"\\n# mixed is target #\\n\")\n",
    "all_model_mixed_LR, mse_LR['mixed'], all_model_mixed_DT, mse_DT['mixed'] = pipeline_given_target('mixed', \n",
    "                                                                                                 data_dict, \n",
    "                                                                                                 para_grid_mixed, \n",
    "                                                                                                 'ALL')\n",
    "\n",
    "MSEs_LR['all'] = mse_LR\n",
    "MSEs_DT['all'] = mse_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# male is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  139.46455130825711\n",
      "best parameters:  {'alpha': 39, 'weight': 0.26} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  132.8651767214339\n",
      "best parameters:  {'max_depth': 11, 'min_samples_split': 79, 'min_samples_leaf': 35, 'weight': 0.23} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 125.20\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 122.56\n",
      "\n",
      "# female is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  103.3144620559952\n",
      "best parameters:  {'alpha': 1e-15, 'weight': 0.01} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  107.53108471480579\n",
      "best parameters:  {'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 12, 'weight': 0.04} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 128.00\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 151.80\n",
      "\n",
      "# mixed is target #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=7.71156e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:148: LinAlgWarning: Ill-conditioned matrix (rcond=1.35182e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "best mse:  102.47456122579362\n",
      "best parameters:  {'alpha': 1e-18, 'weight': 0.5} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  100.19096059463614\n",
      "best parameters:  {'max_depth': 8, 'min_samples_split': 75, 'min_samples_leaf': 69, 'weight': 0.15} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 101.30\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 104.26\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  WEIGHTED\n",
    "###\n",
    "mse_LR = {}\n",
    "mse_DT = {}\n",
    "\n",
    "### tune parameters\n",
    "para_grid_male = {\n",
    "    \"alpha\": [37, 38, 39, 40, 41, 42, 43, 44, 45],\n",
    "    \"max_depth\": [8, 9, 10, 11, 12, 13, 14],\n",
    "    \"min_samples_split\": [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
    "    \"min_samples_leaf\": [31, 32, 33, 34, 35, 36, 37, 38],\n",
    "    \"weight\": [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26]\n",
    "}\n",
    "para_grid_female = {\n",
    "    \"alpha\": [1e-50, 1e-40, 1e-18, 1e-17, 1e-16, 1e-15],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14],\n",
    "    \"min_samples_split\": [9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
    "    \"min_samples_leaf\": [5, 8, 9, 10, 11, 12, 13, 14],\n",
    "    \"weight\": [0.01, 0.02, 0.03, 0.04, 0.05, 0.06]\n",
    "}\n",
    "para_grid_mixed = {\n",
    "    \"alpha\": [1e-18, 1e-17, 1e-16, 1e-15, 1e-14, 1e-13, 1e-12, 1e-10, 1e-8, 1e-7, 1e-6],\n",
    "    \"max_depth\": [6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    \"min_samples_split\": [70, 71, 72, 73, 74, 75, 76],\n",
    "    \"min_samples_leaf\": [63, 64, 65, 66, 67, 68, 69, 70, 71],\n",
    "    \"weight\": [0.1, 0.14, 0.15, 0.16, 0.17, 0.2, 0.25, 0.3, 0.4, 0.5]\n",
    "}\n",
    "\n",
    "print(\"# male is target #\\n\")\n",
    "_, mse_LR['male'], _, mse_DT['male'] = pipeline_given_target('male', data_dict, para_grid_male, 'WEIGHTED')\n",
    "\n",
    "print(\"\\n# female is target #\\n\")\n",
    "_, mse_LR['female'], _, mse_DT['female'] = pipeline_given_target('female', data_dict, para_grid_female, 'WEIGHTED')\n",
    "\n",
    "print(\"\\n# mixed is target #\\n\")\n",
    "_, mse_LR['mixed'], _, mse_DT['mixed'] = pipeline_given_target('mixed', data_dict, para_grid_mixed, 'WEIGHTED')\n",
    "\n",
    "MSEs_LR['weighted'] = mse_LR\n",
    "MSEs_DT['weighted'] = mse_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_pipeline_given_target(target, data_dict, para_grid, srconly_model, model_type):\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    X_train, y_train, X_dev, y_dev, X_test, y_test = get_data_partitions_for_a_target(target, data_dict, 'TGTONLY')\n",
    "\n",
    "    pred = srconly_model.predict(X_train)\n",
    "    X_train = X_train.assign(predictions = pd.Series(pred).values)\n",
    "    \n",
    "    pred = srconly_model.predict(X_dev)\n",
    "    X_dev = X_dev.assign(predictions = pd.Series(pred).values)\n",
    "    \n",
    "    pred = srconly_model.predict(X_test)\n",
    "    X_test = X_test.assign(predictions = pd.Series(pred).values)\n",
    "    \n",
    "    ### standardize data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_dev = scaler.transform(X_dev)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    if model_type == 'Linear Regression':\n",
    "        best_model, best_mse, best_paras = tune_paras_lin_reg(X_train, y_train, X_dev, y_dev, para_grid)\n",
    "    elif model_type == 'Decision Tree':\n",
    "        best_model, best_mse, best_paras = tune_paras_decision_tree(X_train, y_train, X_dev, y_dev, para_grid)\n",
    "    \n",
    "    tune_para_performance_summary(best_mse, best_paras, model_type)\n",
    "\n",
    "    ### evaluate performance on test data\n",
    "    mse_test = evaluate_performance_on_test(best_model, X_test, y_test, model_type)\n",
    "    \n",
    "    return mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# male is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  156.7764521554666\n",
      "best parameters:  {'alpha': 4.3} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 126.73\n",
      "Decision Tree:\n",
      "best mse:  143.21187035324152\n",
      "best parameters:  {'max_depth': 6, 'min_samples_split': 21, 'min_samples_leaf': 2} \n",
      "\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 139.61\n",
      "\n",
      "\n",
      "# female is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  105.03000886739734\n",
      "best parameters:  {'alpha': 3} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 126.82\n",
      "Decision Tree:\n",
      "best mse:  107.6090860969388\n",
      "best parameters:  {'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 17} \n",
      "\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 136.55\n",
      "\n",
      "\n",
      "# mixed is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  114.23369195415152\n",
      "best parameters:  {'alpha': 17} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 109.38\n",
      "Decision Tree:\n",
      "best mse:  113.39635173757296\n",
      "best parameters:  {'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 1} \n",
      "\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 113.68\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  PRED\n",
    "###\n",
    "mse_LR = {}\n",
    "mse_DT = {}\n",
    "\n",
    "para_grid_male = {\n",
    "    \"alpha\": [1, 2, 3, 3.5, 3.6, 3.7, 3.8, 3.9, 4, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 5],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"min_samples_split\": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4, 5, 6, 8, 10]\n",
    "}\n",
    "\n",
    "para_grid_female = {\n",
    "    \"alpha\": [1, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3, 3.1, 3.2, 3.3, 3.4, 3.5],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6],\n",
    "    \"min_samples_split\": [2, 3, 4, 6, 8, 10, ],\n",
    "    \"min_samples_leaf\": [12, 14, 15, 16, 17, 18, 19, 20, 30, 40]\n",
    "}\n",
    "\n",
    "para_grid_mixed = {\n",
    "    \"alpha\": [3.5, 5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"min_samples_split\": [2, 3, 4, 5, 6, 8, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 4, 5, 6, 8, 10]\n",
    "}\n",
    "\n",
    "print(\"# male is target #\\n\")\n",
    "mse_LR['male'] = pred_pipeline_given_target('male', data_dict, para_grid_male, srconly_model_male_LR, 'Linear Regression')\n",
    "mse_DT['male'] = pred_pipeline_given_target('male', data_dict, para_grid_male, srconly_model_male_DT, 'Decision Tree')\n",
    "\n",
    "print(\"\\n\\n# female is target #\\n\")\n",
    "mse_LR['female'] = pred_pipeline_given_target('female', data_dict, para_grid_female, \n",
    "                                              srconly_model_female_LR, 'Linear Regression')\n",
    "mse_DT['female'] = pred_pipeline_given_target('female', data_dict, para_grid_female, srconly_model_female_DT, 'Decision Tree')\n",
    "\n",
    "\n",
    "print(\"\\n\\n# mixed is target #\\n\")\n",
    "mse_LR['mixed'] = pred_pipeline_given_target('mixed', data_dict, para_grid_mixed, \n",
    "                                              srconly_model_mixed_LR, 'Linear Regression')\n",
    "mse_DT['mixed'] = pred_pipeline_given_target('mixed', data_dict, para_grid_mixed, srconly_model_mixed_DT, 'Decision Tree')\n",
    "\n",
    "MSEs_LR['pred'] = mse_LR\n",
    "MSEs_DT['pred'] = mse_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# male is target #\n",
      "\n",
      "Mean squared error of the final model: 125.57\n",
      "Mean squared error of the final model: 125.27\n",
      "\n",
      "\n",
      "# female is target #\n",
      "\n",
      "Mean squared error of the final model: 123.73\n",
      "Mean squared error of the final model: 127.58\n",
      "\n",
      "\n",
      "# mixed is target #\n",
      "\n",
      "Mean squared error of the final model: 108.17\n",
      "Mean squared error of the final model: 105.15\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  LININT\n",
    "###\n",
    "mse_LR = {}\n",
    "mse_DT = {}\n",
    "\n",
    "print(\"# male is target #\\n\")\n",
    "mse_LR['male'] = linint_pipeline_given_target('male', data_dict, srconly_model_male_LR, tgtonly_model_male_LR)\n",
    "mse_DT['male'] = linint_pipeline_given_target('male', data_dict, srconly_model_male_DT, tgtonly_model_male_DT)\n",
    "\n",
    "print(\"\\n\\n# female is target #\\n\")\n",
    "mse_LR['female'] = linint_pipeline_given_target('female', data_dict, srconly_model_female_LR, tgtonly_model_female_LR)\n",
    "mse_DT['female'] = linint_pipeline_given_target('female', data_dict, srconly_model_female_DT, tgtonly_model_female_DT)\n",
    "\n",
    "print(\"\\n\\n# mixed is target #\\n\")\n",
    "mse_LR['mixed'] = linint_pipeline_given_target('mixed', data_dict, srconly_model_mixed_LR, tgtonly_model_mixed_LR)\n",
    "mse_DT['mixed'] = linint_pipeline_given_target('mixed', data_dict, srconly_model_mixed_DT, tgtonly_model_mixed_DT)\n",
    "\n",
    "MSEs_LR['linint'] = mse_LR\n",
    "MSEs_DT['linint'] = mse_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# male is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  147.87158113098255\n",
      "best parameters:  {'alpha': 113} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  122.02631337586082\n",
      "best parameters:  {'max_depth': 22, 'min_samples_split': 15, 'min_samples_leaf': 2} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 123.67\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 145.97\n",
      "\n",
      "# female is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  100.90381965932158\n",
      "best parameters:  {'alpha': 10} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  109.18640225712045\n",
      "best parameters:  {'max_depth': 47, 'min_samples_split': 18, 'min_samples_leaf': 9} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 124.34\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 139.80\n",
      "\n",
      "# mixed is target #\n",
      "\n",
      "Linear Regression:\n",
      "best mse:  102.54567699445481\n",
      "best parameters:  {'alpha': 111} \n",
      "\n",
      "Decision Tree:\n",
      "best mse:  112.37624462310117\n",
      "best parameters:  {'max_depth': 43, 'min_samples_split': 15, 'min_samples_leaf': 6} \n",
      "\n",
      "Linear Regression: \n",
      "Mean squared error of the final model on test data: 103.47\n",
      "Decision Tree: \n",
      "Mean squared error of the final model on test data: 117.87\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# FEDA\n",
    "###\n",
    "mse_LR = {}\n",
    "mse_DT = {}\n",
    "\n",
    "para_grid_male = {\n",
    "    \"alpha\": [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 130],\n",
    "    \"max_depth\": [22, 24, 25, 26, 27, 28, 29, 30, 31],\n",
    "    \"min_samples_split\": [10, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    \"min_samples_leaf\": [2, 3, 4, 5, 6, 7]\n",
    "}\n",
    "\n",
    "para_grid_female = {\n",
    "    \"alpha\": [0.1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    \"max_depth\": [35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50],\n",
    "    \"min_samples_split\": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    \"min_samples_leaf\": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "}\n",
    "para_grid_mixed = {\n",
    "    \"alpha\": [100, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 120, 130],\n",
    "    \"max_depth\": [35, 36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
    "    \"min_samples_split\": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    \"min_samples_leaf\": [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "print(\"# male is target #\\n\")\n",
    "feda_model_male_LR, mse_LR['male'], feda_model_male_DT, mse_DT['male'] = pipeline_given_target('male', \n",
    "                                                                                               data_dict, \n",
    "                                                                                               para_grid_male, \n",
    "                                                                                               'FEDA')\n",
    "\n",
    "print(\"\\n# female is target #\\n\")\n",
    "feda_model_female_LR, mse_LR['female'], feda_model_female_DT, mse_DT['female'] = pipeline_given_target('female', \n",
    "                                                                                                       data_dict, \n",
    "                                                                                                       para_grid_female, \n",
    "                                                                                                       'FEDA')\n",
    "\n",
    "print(\"\\n# mixed is target #\\n\")\n",
    "feda_model_mixed_LR, mse_LR['mixed'], feda_model_mixed_DT, mse_DT['mixed'] = pipeline_given_target('mixed', \n",
    "                                                                                                   data_dict,\n",
    "                                                                                                   para_grid_mixed, \n",
    "                                                                                                   'FEDA')\n",
    "\n",
    "MSEs_LR['feda'] = mse_LR\n",
    "MSEs_DT['feda'] = mse_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "srconly: \n",
      "\n",
      "male: 125.71414171282679\n",
      "female: 137.97842015757604\n",
      "mixed: 102.10633144718793\n",
      "\n",
      "tgtonly: \n",
      "\n",
      "male: 126.83975877139089\n",
      "female: 129.73387925038682\n",
      "mixed: 110.31032170992508\n",
      "\n",
      "all: \n",
      "\n",
      "male: 125.57144214216548\n",
      "female: 137.59197867612195\n",
      "mixed: 101.37151046279537\n",
      "\n",
      "weighted: \n",
      "\n",
      "male: 125.19969623740867\n",
      "female: 127.999112433373\n",
      "mixed: 101.29585518659934\n",
      "\n",
      "pred: \n",
      "\n",
      "male: 126.73327624445406\n",
      "female: 126.81515414051644\n",
      "mixed: 109.37544784603315\n",
      "\n",
      "linint: \n",
      "\n",
      "male: 125.5675684953006\n",
      "female: 123.73018022800925\n",
      "mixed: 108.1725479074162\n",
      "\n",
      "feda: \n",
      "\n",
      "male: 123.67265198173102\n",
      "female: 124.34169419426604\n",
      "mixed: 103.47154600665553\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#  MSE summary\n",
    "###\n",
    "\n",
    "## linear regression\n",
    "for key, value in MSEs_LR.items(): \n",
    "    print(\"\\n\" + key + ': \\n')\n",
    "    for target, val in value.items():\n",
    "        print(target + \": \" + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "srconly: \n",
      "\n",
      "male: 127.63408224636876\n",
      "female: 142.5847805449272\n",
      "mixed: 106.63687096927222\n",
      "\n",
      "tgtonly: \n",
      "\n",
      "male: 141.01239558173333\n",
      "female: 140.41091674958807\n",
      "mixed: 113.68121855573948\n",
      "\n",
      "all: \n",
      "\n",
      "male: 125.71023137081818\n",
      "female: 140.1161744605558\n",
      "mixed: 105.67298695956944\n",
      "\n",
      "weighted: \n",
      "\n",
      "male: 122.56215780517402\n",
      "female: 151.7954928795514\n",
      "mixed: 104.26073977111952\n",
      "\n",
      "pred: \n",
      "\n",
      "male: 139.611828543789\n",
      "female: 136.54625402031562\n",
      "mixed: 113.68121855573948\n",
      "\n",
      "linint: \n",
      "\n",
      "male: 125.26710037272298\n",
      "female: 127.58040492973697\n",
      "mixed: 105.1458105876258\n",
      "\n",
      "feda: \n",
      "\n",
      "male: 144.72612232440073\n",
      "female: 142.5504329881887\n",
      "mixed: 117.87718339284673\n"
     ]
    }
   ],
   "source": [
    "## decision tree\n",
    "for key, value in MSEs_DT.items(): \n",
    "    print(\"\\n\" + key + ': \\n')\n",
    "    for target, val in value.items():\n",
    "        print(target + \": \" + str(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************************************************\n",
    "# *    Title: Hiton diagram\n",
    "# *    Author: David Warde-Farley\n",
    "# *    Date: 25 May, 2020\n",
    "# *    Code version: NN\n",
    "# *    Availability: https://matplotlib.org/3.1.1/gallery/specialty_plots/hinton_demo.html\n",
    "# *\n",
    "# ***************************************************************************************\n",
    "\n",
    "def hinton(matrix, max_weight=None, ax=None):\n",
    "    \"\"\"Draw Hinton diagram for visualizing a weight matrix.\"\"\"\n",
    "    ax = ax if ax is not None else plt.gca()\n",
    "\n",
    "    if not max_weight:\n",
    "        max_weight = 2 ** np.ceil(np.log(np.abs(matrix).max()) / np.log(2))\n",
    "\n",
    "    ax.patch.set_facecolor('gray')\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "    for (x, y), w in np.ndenumerate(matrix):\n",
    "        color = 'white' if w > 0 else 'black'\n",
    "        size = np.sqrt(np.abs(w) / max_weight)\n",
    "        rect = plt.Rectangle([x - size / 2, y - size / 2], size, size,\n",
    "                             facecolor=color, edgecolor=color)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    ax.autoscale_view()\n",
    "    ax.invert_yaxis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## column order: general ##\n",
      "Year\n",
      "[1.2868082835899777, -0.059458824592192455, 1.1967813129472953, -0.27945029929516535]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABcCAYAAABQrm8uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACPUlEQVR4nO3csY6iQADH4fFylVDQbL2P5wMYe3vDQ25lcVtiPVevucQzyvwRv68k6EwI+WUyATa11gJAe7/SEwB4VwIMECLAACECDBAiwAAhv+85ebvd1mEY5poLwCqdz+fvWuvH9fG7AjwMQ9ntds+bFcAbOB6PX/86bgsCIESAAULu2oJ4xH6/L33ftxpu8aZpKuM4pqcBBDULsPj+5Hosl8WCBUIrtiDgyrvHtxTXoBUBBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIafZBdoBHnE6ncrlcImN3XVcOh8PT/9cKGHgJqfjOObYAA4QIMECIAAOECDBAiAADhAgwQIgAA4R4EYObHnkAfq4H2GENrIC56ZGH0JMPz8PSCTBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDA3dV0X+S2snc9RcpPPScI8rIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYeAnJl3rmGtuLGMBLWOMLQVbAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgxXpmlKTyHONWij2QfZp2kqfd+3Gm7x3ODLNY5jegq8iWYBdlMD/GQLAiBkU2v9/5M3mz+llK/5pgOwSp+11o/rg3cFGIDnsQUBECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBDyFyCWULewct3yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VR1 Band\n",
      "[3.4736192440427613, 1.1426060841794785, 2.3825444136232092, -0.2071477056988738]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABpCAYAAAAEGfkwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACb0lEQVR4nO3dsY6iQADH4fGylVjQbH2P5wMYe3vDQ25lcVtiPdd6GwvdHfkf8H0lMTih+GUyMLCptRYApvcrPQCAtRJggBABBggRYIAQAQYIEWCAkLdnfrzdbmvf968aC8AiXS6Xz1rr+9fjTwW47/uy3+/bjQpgBU6n08e945YgAEIEGCDkqSWInzgcDmW32031d4syjmMZhiE9DKCxyWbA4vt9rh0skyUIgBABBggRYIAQAQYIEWCAkMkeQ4O58yilRyJbMwOGB609vqW4Bq0JMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOE2Am3cnPc3WU3FkthBrxyc4tvKfMcM9wjwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACFexgMs0vl8Ltfrtcm5uq4rx+OxyblumQEDi9Qqvq3PdUuAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYWKSu6/7Lc93yTThgkV7xDbfWzIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBHjlxnFMD+Fpcxwz3ONlPCs3DEN6CLBaZsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDA+yBdo1aM1WZHiQbdu0ZgYMECLAACECDBAiwAAhkwXY3dPvc+1gmSZ7CsIdZIB/WYIACBFggJBNrfXxH282f0opH68bDsAi/a61vn89+FSAAWjHEgRAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQMhfKKJQ9aBUmQUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_1\n",
      "[-2.3637689239615733, -1.1798082654834472, -0.6732191208956896, -0.5107415375824171]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABaCAYAAACG94wzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACKklEQVR4nO3bq47CQBiG4ekGRU0Nei+PK6jHc5WrELsWPSsIYgkCsm2/Hp5HNoT+qXgzPUxTay0ATO8jPQDAVgkwQIgAA4QIMECIAAOECDBAyO6dH+/3+9p13VizAKzS5XL5qbUeHo+/FeCu68rxeBxuKoANOJ1OX8+OewQBEPLWCvg/zudzuV6vU51uttq2LX3fp8cAZmCyFbD43rgOwJ1HEAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQMtlOOHKWugvRrkHWzgp4A5YY31KWOze8SoABQgQYIESAAUIEGCDEVxAwoDl9ceIrkvmzAoYBzSW+pcxrFp6zAgYWI3WHMdbdhBUwsBipVf1Y5xVggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWBgMdq2XdV5d6P8K8AI+r5PjzAoK2CAEAGGAaVukZ+Z0yw85xEEDGhtt8iMywoYIESAAUIEGCBEgDdgqS9jljo3vMpLuA3wYgjmyQoYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUImC7BdTTeuA3A32U44u7EA/vIIAiCkqbW+/uOm+S6lfI03DsAqfdZaD48H3wowAMPxCAIgRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIOQXmQNP//F7jRQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_2\n",
      "[0.011356547736394685, -0.49093802597465397, 0.5829414117148276, -0.08064683800378127]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABhCAYAAADoSntdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACW0lEQVR4nO3dsWrjQBiF0fGylaVCTeo8nh9AqHdv9JCpXGzKcT1bLhsCiYmta8nnlGLAPyo+hsFidq21AsDyfqUHAHhWAgwQIsAAIQIMECLAACG/r1m83+/bMAz3mgVgk87n83tr7eXj86sCPAxDORwOt5sK4Akcj8e3z547ggAIEWCAkKuOIGCNxnEsfd+nx3hotdYyz3N6jKdjB8zmie/XvKMMAQYIcQQRcDqdyuVySY/xELquK9M0pceACDvgAPH9x7vgmQkwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhLgTDlilJe9WvNfdhXbAwCoteZ/gvX5LgAFCBBggRIABQgQYIESAAUIEGCBksf8Bj+NY+r7/cl2ttczzvMBEAFmL7YC/E99r1gGsnSMIgBABBggRYIAQAQYIEWCAEAEGCBFggBABBghZLMC11puuA1i7xT5F9nkxwP8cQQCECDBAiAADhAgwQIgAA4QIMECIAAOECDCwSl3Xrf63FvsQA+CWpmlKj/BjdsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsABS95l9ei8C56ZO+ECtnCXFfBzdsAAIQLM5tVa0yM8PO8owxEEmzfPc3oE+JQdMEDIrrX2/cW73Z9Sytv9xgHYpNfW2svHh1cFGIDbcQQBECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBDyF3oYUJ3No6BDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_3\n",
      "[0.060532856862850815, -0.3244233128410488, 0.38495616970390323, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAACCCAYAAAB4mhJxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACt0lEQVR4nO3YMU7jUBRAUWeUiqRIQz3LYwFRenrkRVJRMKWpPT2iICjxNck5pRXlP9nS1dfbzPM8ALC8P/UAAPdKgAEiAgwQEWCAiAADRAQYILI958cPDw/z4XC41iwAN+nt7e3fPM+Pn5+fFeDD4TA8PT1dbiqAO/D8/Pz61XMrCICIAANEBBggctYOGLiu4/E47Pf7egw+maZpGMfx4v/rBgwrIr7rdK3vIsAAEQEGiNgB35iXl5fh4+OjHuPu7Ha74XQ61WPwy7gB3xjxbXjv/IQAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0S2Sx10PB6H/X6/1HFnm6ZpGMexHgO4I4vdgNcc32FY/3zA7bGCAIgIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRBYL8DRNSx31I2ufD7g926UOGsdxqaMAfgUrCICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAN+Y3W5Xj3CXvHd+YlsPwGWdTqd6BOCb3IABIgIMEBFgWJFpmuoR+MK1vosdMKzIOI71CCzIDRggIsAAEQEGiGzmef7+jzeb92EYXq83DsBN+jvP8+Pnh2cFGIDLsYIAiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiPwHjR1DfP6U8gAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_4\n",
      "[1.043591317905697, 0.3698842813676182, 0.4336294594570939, 0.24007757708098745]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABWCAYAAADxNUxIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACI0lEQVR4nO3bMW7bMBiGYbrIZGjQkrnH8wF8AV9Ah8zkIR25M3OCtqlrSx8tPs8oGNbv5TXxAzy01goA2/uRHgBgVAIMECLAACECDBAiwAAhAgwQ8nLLh4/HY5vnea1ZAHbper3+aq29fn1+U4DneS6n0+lxUwEM4HK5vP3uuRUEQMhNJ+B7nM/nMk3TVq/rRq21LMuSHgPo0GYn4BHjW8q4vxv4nhUEQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMEDIZleRYa96v2bvOny/nIDhTj3Ht5T+5xuZE/CAejyxOaUxIifgAfUW31L6nAnWJsAAIVYQwNNIrc/WWpE5AQNPI7WqWuu9AgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDDyNWuuu3vuyyrcCrGBZlvQID+UEDBAiwAAhAjyg1B7tb3qcCdZmBzygve3R0mqtZZqm9Bh/5M+tXwIMd/KHxv+yggAIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCNkswKNehxz1dwPf2+wqsuuaAJ9ZQQCEHFpr//7hw+G9lPK23jgAu/Sztfb69eFNAQbgcawgAEIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCPgCr0VE7NUNg3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_5\n",
      "[-2.857214840092825, -2.0307743289974645, -0.5820784704928077, -0.24436204060255778]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABhCAYAAADoSntdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACQklEQVR4nO3dvW7CMBiGUVN1IkuWzr08roCdnavsxNCuzO7cH1VFrf0S+5wxQmAYHlnJJ7OrtRYA+ntILwBgVgIMECLAACECDBAiwAAhAgwQ8njLi/f7fV3XtdVaAIZ0uVzeaq1Pn6/fFOB1XcvhcPi/VQFM4HQ6vXx33S0IgJCbdsB/cT6fy/V67fVxm7MsSzkej+llAB112wGL78/8PjAftyAAQgQYIESAAUIEGCCk2xQE/cw6cWKShK2xAx7QjPEtZd7vzXYJMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4Q4DQ0au4fT6ZwUd5/sgKGxdHzvZQ18JcAAIQIMECLAACECDBBiCgIYSoupk1ZTJHbAwFBaTHy0miIRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQaGsizLJt6zFP+KDAymxb8Xt2IHDBAiwAAhAgwQIsAAIQIMjbV6gr61NfCVKQhobEtP5enLDhggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBHhAs558Nev3ZruchjYgp2/BNtgBA4QIMECIAAOECDBASLcAe0L9M78PzKfbFIQn8wAfuQUBELKrtf7+xbvdaynlpd1yAIb0XGt9+nzxpgAD8H/cggAIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCHkHTelQDYAhhHsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_6\n",
      "[0.6771478325214739, 0.5015336608451821, 0.13643492729371928, 0.03917924438257379]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABgCAYAAAAjFqj4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACQElEQVR4nO3dPW7CMACGYVN1QgxZmHs8DsAFuACH7MTQjtnduX9SURN/xH6eMULEZHhlxZbZ1VoLAO09pQcAMCoBBggRYIAQAQYIEWCAEAEGCHm+58P7/b5O07TWWAC6dLvd3mutx6/X7wrwNE3ldDotNyqAAVwul9efrnsFARBy1wz4P87nczkcDq1utynzPJfr9ZoeBtBYsxmw+P7Os4ExeQUBECLAACECDBDSbBGOtkZc9LSYydaYAXdqtPiWMuZvZtsEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCDEcZTQSPqIUMd1Ph4zYGgkfVxm+v58J8AAIQIMECLAACECDBAiwAAhtqEBXVti+99aW/jMgIGuLbH9bq0tfAIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgx0bZ7nh/iOn/hLIqBra/yV0FLMgAFCBBggRIABQgQYIESAAUIEGBpZayvTVu7Pd7ahQSOPvB2KDDNggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBAB7tSIRw+O+JvZNsdRdsrRh/D4zIABQgQYIESAAUKaBdgCye88GxhTs0U4i0IAn3kFARCyq7X+/cO73Vsp5XW94QB06aXWevx68a4AA7AcryAAQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUI+AFcvUSsO6tdJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_7\n",
      "[1.549692659360011, 0.8741141610363422, 0.7549294676156965, -0.07935096929202685]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABlCAYAAABz2zlLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACY0lEQVR4nO3dsY7aQBiF0SFKhSncbJ3H4wEQPT3yQ25FsSlNPSmjrChi2fjC+JzSQmZM8elnpJF3tdYCwPp+pBcAsFUCDBAiwAAhAgwQIsAAIQIMEPJzyof3+33t+/5ZawFo0u12+11r/fh+fVKA+74vx+NxuVUBbMDlcvl8dN0WBECIAAOETNqCmON0OpXD4bDW1729cRzLMAzpZQBPtNoELL7T+L2gfbYgAEIEGCBEgAFCBBggRIABQgQYIESAAUJWO4hBzhYOwTi4wjsyAW9A6/EtZRvPSHtMwDBTi/8w/KNYhwkYZmotvqW0+UyvSIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCDEGzGApl2v13K/32fdo+u6cj6fF1rRXyZgoGlz47vUPR4RYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGmtZ13Uvc4xFvxACa9ow3WSzFBAwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDDON45hewuJafKZX5I0YMNMwDOkl8KZMwBuwhWlmC89Ie0zAG2BCg9dkAgYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAkNUC7KTSNH4vaN9qJ+GcxgL4ly0IgJBdrfX/P7zbfZVSPp+3HIAm/aq1fny/OCnAACzHFgRAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQMgfsxVQ7c6Qp0YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_8\n",
      "[1.3151777592024554, 1.3221912430607092, -0.11122365785987949, 0.10421017400162624]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABfCAYAAADWOh2AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACS0lEQVR4nO3dsariQBiG4bhYmRRpTr2X5wUEe3vJRZ7K4mw51rPFNnJQWDkxXzTPU4bwZxjwRaaZTa21AWB+v9ILAFgrAQYIEWCAEAEGCBFggBABBgjZPvLybrerfd8/ay0Ab+l8Pv+ptX58f/5QgPu+b/b7/XSrAliB4/H4eeu5IwiAkIf+AbM8wzA0Xdell7FIpZRmHMf0MuCu2QIsFLf9NBL29D57w9LNdgThx3CbfYH1cgYMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAh2/QCYM1Op1NzuVwmm9e2bXM4HCabx3MJMARNGd9nzHtlwzA0XddNMquU0ozjOMmsa44ggLc0VXynnnVNgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGHhLpZRFzrrmTjgIatt28ks5+ecZd7hNTYAhyA3G6+YIAiBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIGS2AJdS5vrUS/npvtjX++wNS7ed60PjOM71qVWxr/C6HEEAhGxqrf//8mbz1TTN5/OWA/CWftdaP74/fCjAAEzHEQRAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQMhfk8pTvs5mq5IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_9\n",
      "[1.134356796595571, 1.102841006847857, 0.10117325960857436, -0.06965746986086876]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABaCAYAAACG94wzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACM0lEQVR4nO3dsW7bMBiFUbroZGXQkrmP5wcQvHs39JCZPLSjPLND0CVIgDohdWP5nFGwZOIfPhAaxF2ttQCwvh/pBQA8KgEGCBFggBABBggRYIAQAQYI+XnLj/f7fR3HsddaADbpcrn8qbU+v71+U4DHcSyHw6HdqgAewOl0ennvulcQACE37YC/Ypqm8vT0tNbffVvLspR5nps/13z7zRZ6WW0H/Ohx+KfXHMzXDLg/XkEAhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4Ssdiw98L5pmpqd6LwsS5nnucmz6M8OGMJaxbf1s+jPDhjYvPP5XK7X66fvH4ahHI/Hhit6ZQcMbN5X4tvi/o8IMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDCwecMwRO//iA+yA5vX42PqLdgBQ9iyLN/yWfRnBwxhDtF8XHbAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhqwXYcdmves3BfM2A+7PasfSO3u7LfOH+eAUBELKrtf7/j3e736WUl37LAdikX7XW57cXbwowAO14BQEQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMEPIXf8tQ02INy4AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_10\n",
      "[-0.5578702845657216, -0.297000464163295, -0.26086982040242845, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABxCAYAAADrnHnGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACXklEQVR4nO3csW7aUBiAUVNlgoUlcx+PJ2Bn5ykzZUhX5tu5KGoKjf0JfM5oIbj28On3lbibMcYEwPJ+1AsAWCsBBogIMEBEgAEiAgwQEWCAyMstH95ut2O/38+1FoCn9P7+/muM8Xp9/aYA7/f76XA4fN+qAFbgdDq9fXbdFgRARIABIjdtQfyP8/k8XS6XpX5uNXa73XQ8HutlAHdYbAIW33l4rvC4bEEARAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYILLYWRCs15rPAXFWB39jAmZ2a43vNK373vmaCRi4y5rebOZ6kzEBA3dZS3ynab57FWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADd9ntdvUSFjPXvb7M8q3A0zsej/USHp4JmNmtaVK6tuZ752smYGZnUoLPmYABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEFkswP4TPw/PFR7XYmdBOA8A4E+2IAAiAgwQ2Ywx/v3Dm83HNE1v8y0H4Cn9HGO8Xl+8KcAAfB9bEAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwACR3+gaQsrolnvDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnic group of student_11\n",
      "[-0.013001721564345743, -0.66323860630787, 0.7280221544889277, -0.07778526974541597]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABrCAYAAABJ0Vg7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACgklEQVR4nO3csY6bQBiFURy58rig2TqP5wew6N1bPORWLjYl1JM6qxRL4uEu+JwSIfOL4tNoNPhQa+0AWN+P9AAAr0qAAUIEGCBEgAFCBBggRIABQo5Lbj6dTrXv+1azAOzS4/H4VWt9+3x9UYD7vu8ul8vzpgJ4Abfb7f1v121BAIQIMEDIoi0I2ILr9dqdz+f0GJs2TVM3jmN6jN2zAmZ3xPf/eYfrsAJu7H6/d/M8p8fYlFJKNwxDegxozgq4MfFdzjvjVQgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAyDE9AMC/ut/v3TzPzZ9TSumGYXj671oBA5u1RnxbPkeAAUIEGCBEgAFCBBggRIABQgQYIGS1c8BLzuu1OnMH8J2stgJeco5urbN9AEm2IABCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQlYLcCmlyb0AW7Xaf0H4bweAP9mCAAgRYIAQAQYIEWCAEAEGCBFggBABBjZrrW8GWj1ntXPAAM+29e8LrIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBLixUkp6hM3xzngVx/QAezcMQ3oE4JuyAmZ3pmlKj7B53uE6rIDZnXEc0yPAl1gBA4QIMEDIodb69ZsPh4+u697bjQOwSz9rrW+fLy4KMADPYwsCIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCDkN7M1UGnlX4HOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School denomination_1\n",
      "[-0.5990047448075916, -0.28363187127750933, -0.40910217150199596, 0.09372929797179239]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABbCAYAAABNq1+WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACQklEQVR4nO3bsY7aQBiF0SHaClO42TqPxwMg9/TID7kVRVKaelKstghKgbPYF9vnlBbCPy4+jWbMrtZaAJjfj/QAAFslwAAhAgwQIsAAIQIMECLAACFvYz683+9r27ZTzQKwStfr9Xet9f3++qgAt21bjsfj86YC2IDz+fzxr+u2IABCRq2Av+NyuZTb7TbX7V5W0zSl67r0GMALmG0FLL6fPAfgiy0IgBABBggRYIAQAQYIme0tCFiDNb/N4w2d+VkBwwhrjW8p6/5tr0qAAUIEGCBEgAFCHMJtxFIPjxwMsWZWwBuxxPiWsty54RECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAh/gkHLNbpdCqHw2Hy+wzDUPq+f/r3WgEDizVHfKe8jwADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADizUMw6Lv8zbJtwLMoO/79AjfYgUMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECvBFN06RH+C9LnRse4Z9wG9F1XXoE4I4VMECIAAOECDCMsOY96TX/tldlDxhGsJfOM1kBA4QIMECIAAOECDBAyGwBdsL6yXMAvsz2FoTTY4C/2YIACNnVWh//8G73q5TyMd04AKv0s9b6fn9xVIABeB5bEAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIX8AIsdQSaYpBI4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School denomination_2\n",
      "[0.5139831570622467, 0.9129933521496391, 0.11263854425597965, -0.5116487393433703]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABnCAYAAAA+E5hAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACaElEQVR4nO3csY7aQBiF0SHaClO42TqPxwMg9/QrP+RWFElp6km/iqIY4bmL55zSQvCb4tNopJlDrbUA0N6P9AAAvRJggBABBggRYIAQAQYIeVvz4ePxWMdx3GoWgF263W6/a63vX5+vCvA4juV8Pj9vKoAOXK/Xz789twUBECLAACGrtiDYzuVyKafTKT3Gy1mWpczznB4DHmIF/E2I72P8b7wyAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAkGYn4Xo66eV0Fr34+Pgo9/s9PcbmhmEo0zQ9/XubrYB7iW8pfb0rfeshvqVs9562IABCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggpNl9wLAXre+2dr/0flkBw0qt73t2v/R+CTBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiAADhAgwQIgAA4QIMECIAAOECDBAiADDSsuy7Pr3aOctPQC8mnme0yOwE1bAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBDSLMA93Wna07vSt2EY0iM0sdV7NrsP2B2qsD/TNKVHeGm2IABCBBggRIABQgQYIESAAUIEGCBEgAFCBPibcHjjMf43Xlmzgxj8m4Mq0B8rYIAQAQYIOdRa///Dh8OvUsrnduMA7NLPWuv714erAgzA89iCAAgRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYI+QNTLFDtnITz+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "School denomination_3\n",
      "[0.08502158774547543, -1.4449801314821726, 1.7911594074779718, -0.26115768825030355]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAByCAYAAABtCAtoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACl0lEQVR4nO3doW7bUBiAUWcaagJCivd4fYAovLzyQxYVbNDFHl41sESxv8Q7B1qW9cvg09W1pbub53kAYH3f6gEA/lcCDBARYICIAANEBBggIsAAke+X3Pz09DQfj8elZgHYpI+Pj1/zPD9/vX5RgI/H4/Dy8nK7qQD+A6+vr+9/u24LAiAiwACRi7Yg4B6dTqfhcDjUY2zWNE3DOI71GJtkBczDE99leb/LEWCAiAADRAQYIOIj3Are3t6Gz8/PeoyHtN/vh/P5XI8Bi7ACXoH4Xs+7Y8sEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBAxKnIwF27h1PFlzqd2woYuGt1fJecQYABIgIMEBFggIgAA0QEGCAiwACR1f4DPp1Ow+FwuMmzpmkaxnG8ybMAKqutgG8V31s/C6BiCwIgIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggslqAp2m6y2cBVFY7E84ZbgB/sgUBEBFggIgAA0QEGCAiwAARAQbu2n6/r0dYbIbVfkMDuMb5fK5HWIwVMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiACv4B5OdX1U3h1b5lTkFWz5VFfgelbAABEBBogIMEBEgHl40zTVI2ya97scH+F4eOM41iPAVayAASICDBDZzfP87zfvdj+HYXhfbhyATfoxz/Pz14sXBRiA27EFARARYICIAANEBBggIsAAEQEGiAgwQESAASICDBD5DZi8UL9Io1z7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VR Band of Student_1\n",
      "[-5.98442582942532, -2.265197285856008, -2.8920965188547973, -0.8271320247145092]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABiCAYAAABu3gnzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACRklEQVR4nO3csW7CMBiFUVN1IksW5j4eT5CdnafsxNCuzO7cqhKFEl/ZOWeMEDEZPv1EcXa11gJAey/pBQBslQADhAgwQIgAA4QIMECIAAOEvN7z4f1+X+d5XmstAEO6XC6ftdbDz+N3BXie53I8Hp+3KoANOJ1O778ddwsCIOSuCfg/zudzuV6vrU7XpWmayrIs6WUAjTSbgMX3NtcItsUtCIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCGn2LggYyUjvNvEOkhwTMDxglPiWMtZv6Y0JeIN6nN5MaYzIBLxBvcW3lD7XDLcIMECIAAOECDBAiAADhAgwQIgAA4QIMECIjRhAl1puKFprI5AJGOhSy805a51LgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRICBLk3T1P25Xlf5VoCVLcuSXsK/mYABQgQYIESAAUIEGCBEgAFCBBggRIABQgR4g1o+wP4sPa4ZbrERY4NGeIAdRmAChgeMNJGP9Ft6YwKGB/gXwTOYgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIKRZgO03v801gm1p9i4Ie+cBvnMLAiBkV2v9+4d3u49Syvt6ywEY0lut9fDz4F0BBuB53IIACBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBgj5AvUnUA9TORJKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VR Band of Student_2\n",
      "[6.7107301890140665, 1.938060093170545, 4.0510325418849895, 0.7216375539586161]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABmCAYAAAD1T0vlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACVElEQVR4nO3bMW7CMBiGYVN1QgxZmHs8DsAFuEAO2YmhHbO7c6sOpCX+5Ph5xggRw/DKsvwfaq0FgPZe0gsAGJUAA4QIMECIAAOECDBAyOuaDx+PxzpN01ZrAdil+/3+WWs9/3y+KsDTNJXL5fK8VQEM4Ha7vf/23BEEQIgAA4SsOoL4j+v1Wk6nU6vX7cKyLGWe5/QygI002wGL73r+M9g3RxAAIQIMECLAACECDBAiwAAhAgwQIsAAIc0GMaB3ow0TGQTanh0wPGik+JYy3u9NEGCAEAEGCBFggBABBggRYIAQAQYIEWCAEIMYg+tluMBQAHtkBzy4HuJbSj/rhDUEGCBEgAFCBBggRIABQgQYIESAAULcAwa61uIu+1b30O2Aga61uCO+1TsEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAga4ty9LtO143+VaARuZ5Ti/hz+yAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEeHAtLrE/Qy/rhDUMYgyu50vs0Ds7YIAQAQYIEWCAEAEGCBFggBABBggRYIAQAYYHjTYMMtrvTTCIAQ8ytMKz2QEDhAgwQIgAA4QIMECIAAOECDBASLMAu1O4nv8M9q3ZPWB3KAG+cwQBECLAACGHWuvjHz4cPkop79stB2CX3mqt558PVwUYgOdxBAEQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMEPIFfsFRN3mTrywAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VR Band of Student_3\n",
      "[-0.7263043595888974, -0.48848145792467623, 0.3357597572019005, -0.5735826588659968]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABcCAYAAABQrm8uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACRElEQVR4nO3asW7iQBSG0WGVClO4Sb2PxwMg9/SRHzIVxW5p6tk6aKVdJ9h/7DmntJC4pvh0PeZQay0ArO9HegCAVgkwQIgAA4QIMECIAAOEvMz58PF4rH3fLzULwC7dbrfftdbXx+uzAtz3fTmfz8+bCqAB1+v1/W/XHUEAhAgwQMisI4iveHt7K/f7fa2v+/a6rivDMKTHAIJW24DF9yO/B+AIAiBEgAFCVjsDBvajtXc6S72zsQEDs7UU31KWu18b8MbtfRPxbxH2zAa8cXuObyn7vz/aJsAAIQIMECLAACFewsGDy+VSTqdTeozZpmkq4zimx2AGGzA82GJ8S9nu3C0TYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWB4ME1TeoRP2ercLXtJDwDfzTiO6RFohA0YIESAAUIEGCBEgDeu67r0CIva+/3RNi/hNm4YhvQIwCfZgIHZWnsyWep+bcDAbJ68nsMGDBAiwAAhqwW4tTOjf/F7AKudATszAvjIEQRAyKHW+v8fPhx+lVLelxsHYJd+1lpfHy/OCjAAz+MIAiBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCBBgg5A/4elBLyXp1CgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###\n",
    "#  plot coefficients of linear regression model\n",
    "###\n",
    "\n",
    "## male is target\n",
    "\n",
    "print(\"## column order: general ##\")\n",
    "coefs = feda_model_mixed_LR.coef_\n",
    "\n",
    "column_names = list(male_df.columns.values)\n",
    "column_names.remove('Exam Score')\n",
    "\n",
    "increment = len(column_names)\n",
    "# print(increment)\n",
    "# print(len(coefs))\n",
    "\n",
    "for column in column_names:\n",
    "    index = column_names.index(column)\n",
    "    print(column)\n",
    "    ind_list = [index, index + increment, index + 2*increment, index + 3*increment]\n",
    "    \n",
    "    corresponding_coefs = [ coefs[i] for i in ind_list]\n",
    "    print(corresponding_coefs)\n",
    "    transformed_coefs = []\n",
    "    for value in corresponding_coefs:\n",
    "        transformed_coefs.append([value])\n",
    "    \n",
    "    hinton(transformed_coefs, max_weight=None, ax=None)\n",
    "    plt.show()\n",
    "#     print(corresponding_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-bb4a490c79d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# hinton([[a[0]], [a[1]], [a[2]], [a[3]]], max_weight=None, ax=None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtransformed_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mhinton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-bb4a490c79d0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# hinton([[a[0]], [a[1]], [a[2]], [a[3]]], max_weight=None, ax=None)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtransformed_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mhinton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not float"
     ]
    }
   ],
   "source": [
    "a = [0.001, 2, 3, 4]\n",
    "\n",
    "# hinton([[a[0]], [a[1]], [a[2]], [a[3]]], max_weight=None, ax=None)\n",
    "\n",
    "transformed_a = [[a[i]] for i in a]\n",
    "hinton([[a[0]], [a[1]], [a[2]], [a[3]]], max_weight=None, ax=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
